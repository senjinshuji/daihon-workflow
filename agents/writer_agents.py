#!/usr/bin/env python3
"""
Writer Agent - A flexible, prompt-driven creative agent for BB-project.
"""
import json
import os
import re
from typing import List, Dict

# anthropicãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ä»–ã®APIå‘¼ã³å‡ºã—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æƒ³å®š
# from some_api import call_llm 

class WriterAgent:
    """
    A single, flexible writer agent that generates scripts based on a dynamic prompt.
    The persona and instructions are not hardcoded but provided in the prompt.
    """
    
    def __init__(self, writer_id: str):
        self.writer_id = writer_id
        self.model = "claude-3-sonnet-20240229" # or another powerful model

    def _call_anthropic_api(self, prompt: str) -> str:
        """
        Placeholder for calling a powerful language model like Claude 3.
        In a real implementation, this would use the anthropic library,
        handle API keys, and include error handling.
        For now, it returns a structured JSON string for simulation.
        """
        print(f"ğŸ¤– {self.writer_id}: LLM APIå‘¼ã³å‡ºã—ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰...")
        # Simulate a delay for the API call
        import time
        time.sleep(5)

        # This is a mock response. A real LLM would generate this based on the prompt.
        mock_scripts = [
            f"ã€{self.writer_id}ä½œ: å°æœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1ã€‘\nçµå©šå¼ã®ã‚¹ãƒ”ãƒ¼ãƒã€ç·Šå¼µã—ã¾ã™ã‚ˆã­ï¼Ÿã€ŒãŠã‚ã§ã¨ã†ã€ã®æ°—æŒã¡ã€ã—ã£ã‹ã‚Šä¼ã‚ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ... (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå°æœ¬)...",
            f"ã€{self.writer_id}ä½œ: å°æœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2ã€‘\nã€Œæ„Ÿå‹•ã®ã‚¹ãƒ”ãƒ¼ãƒã ã£ãŸã€ã£ã¦è¨€ã‚ã‚ŒãŸã„ã‚ãªãŸã¸ã€‚å®Ÿã¯ã€ãŸã£ãŸ3ã¤ã®ã‚³ãƒ„ãŒã‚ã‚‹ã‚“ã§ã™ã€‚... (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå°æœ¬)...",
            f"ã€{self.writer_id}ä½œ: å°æœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3ã€‘\nå‹äººä»£è¡¨ã‚¹ãƒ”ãƒ¼ãƒã§ã€æ–°éƒã®æ˜”ã®å¤±æ•—è«‡ã‚’è©±ã™ã®ã¯ã‚‚ã†å¤ã„ï¼ä»Šã€å¿ƒã«éŸ¿ãã®ã¯... (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå°æœ¬)...",
            f"ã€{self.writer_id}ä½œ: å°æœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ4ã€‘\nãƒ‡ãƒ¼ã‚¿ã§è¦‹ã‚‹ã€æˆåŠŸã™ã‚‹çµå©šå¼ã‚¹ãƒ”ãƒ¼ãƒã€‚9å‰²ã®äººãŒçŸ¥ã‚‰ãªã„ã€ãŸã£ãŸ1ã¤ã®å…±é€šç‚¹ã¨ã¯ï¼Ÿ... (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå°æœ¬)...",
            f"ã€{self.writer_id}ä½œ: å°æœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ5ã€‘\nã‚¹ãƒãƒ›ã®ãƒ¡ãƒ¢ã‚’èª­ã‚€ã ã‘ã®ã‚¹ãƒ”ãƒ¼ãƒã€ã‚„ã‚ã¾ã›ã‚“ã‹ï¼Ÿã‚ãªãŸã®è¨€è‘‰ã§ã€æœ€é«˜ã®ç¥ç¦ã‚’ã€‚... (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå°æœ¬)..."
        ]
        
        mock_response = {"scripts": mock_scripts}
        
        print(f"ğŸ¤– {self.writer_id}: LLM APIå¿œç­”å—ä¿¡ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
        return json.dumps(mock_response)

    def create_scripts_from_prompt(self, full_prompt: str) -> List[str]:
        """
        Generates multiple script variations from a single, comprehensive prompt.
        The prompt should contain the persona, instructions, and task.
        """
        print(f"âœï¸ {self.writer_id}: æ–°ã—ã„äººæ ¼ã¨æŒ‡ç¤ºã«åŸºã¥ãã€5æœ¬ã®å°æœ¬åˆ¶ä½œã‚’é–‹å§‹...")

        # The system prompt sets the stage for the AI's task.
        system_prompt = """
ã‚ãªãŸã¯ã€ä¸ãˆã‚‰ã‚ŒãŸäººæ ¼ã¨æŒ‡ç¤ºæ›¸ã‚’å®Œç’§ã«ç†è§£ã—ã€å¤šæ§˜ãªã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å‡ºã™ãƒ—ãƒ­ã®å‹•ç”»åºƒå‘Šå°æœ¬ä½œå®¶ã§ã™ã€‚
æœ€çµ‚çš„ãªã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¯ã€å¿…ãšæŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""

        # The user prompt combines the instructions from the files with the specific task.
        final_user_prompt = f"""
{full_prompt}

---
ã€æœ€çµ‚ã‚¿ã‚¹ã‚¯ã€‘
ä¸Šè¨˜ã®äººæ ¼ã¨æŒ‡ç¤ºæ›¸ã«å®Œå…¨ã«ãªã‚Šãã‚Šã€ä»¥ä¸‹ã®è¦ä»¶ã§5æœ¬ã®å‹•ç”»åºƒå‘Šå°æœ¬ã‚’åˆ¶ä½œã—ã¦ãã ã•ã„ã€‚

1.  **å¤šæ§˜æ€§**: 5æœ¬ã¯ãã‚Œãã‚Œç•°ãªã‚‹åˆ‡ã‚Šå£ã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€ã€ŒåŸºæœ¬ã€ã€Œæ„Ÿæƒ…å¼·èª¿ã€ã€Œæ„å¤–ãªäº‹å®Ÿã€ã€Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¸ã®å•ã„ã‹ã‘ã€ã€Œå¤§èƒ†ãªææ¡ˆã€ãªã©ã€å‰µé€ æ€§ã‚’ç™ºæ®ã—ã¦ãã ã•ã„ã€‚
2.  **å“è³ª**: å„å°æœ¬ã¯ã€ãã‚Œå˜ä½“ã§æˆç«‹ã™ã‚‹å®Œæˆåº¦ã‚’æŒã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
3.  **å½¢å¼**: çµæœã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ã¯ "scripts" ã¨ã—ã€å€¤ã¯5æœ¬ã®å°æœ¬æ–‡å­—åˆ—ã‚’å«ã‚€é…åˆ—ã¨ã—ã¾ã™ã€‚

ã€å‡ºåŠ›å½¢å¼ã®ä¾‹ã€‘
{{
  "scripts": [
    "1æœ¬ç›®ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ...",
    "2æœ¬ç›®ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ...",
    "3æœ¬ç›®ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ...",
    "4æœ¬ç›®ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ...",
    "5æœ¬ç›®ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆ..."
  ]
}}
"""
        # In a real implementation, you would use the 'anthropic' library like this:
        # client = anthropic.Anthropic(api_key="YOUR_API_KEY")
        # response = client.messages.create(
        #     model=self.model,
        #     max_tokens=4096,
        #     system=system_prompt,
        #     messages=[{"role": "user", "content": final_user_prompt}],
        #     response_format={"type": "json_object"},
        # )
        # raw_json_response = response.content[0].text
        
        # For this project, we use our simulation function.
        raw_json_response = self._call_anthropic_api(final_user_prompt)

        try:
            # The response is expected to be a JSON string.
            data = json.loads(raw_json_response)
            scripts = data.get("scripts", [])
            if isinstance(scripts, list) and len(scripts) == 5:
                print(f"âœ… {self.writer_id}: 5æœ¬ã®å°æœ¬ç”Ÿæˆã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                return scripts
            else:
                print(f"âŒ {self.writer_id}: LLMã‹ã‚‰ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚ received: {scripts}")
                return [f"ã‚¨ãƒ©ãƒ¼: LLMã‹ã‚‰ã®å¿œç­”å½¢å¼ãŒä¸æ­£ã§ã—ãŸã€‚{raw_json_response}"] * 5
        except json.JSONDecodeError:
            print(f"âŒ {self.writer_id}: LLMã‹ã‚‰ã®å¿œç­”ãŒJSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return [f"ã‚¨ãƒ©ãƒ¼: LLMã®å¿œç­”ãŒJSONã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚{raw_json_response}"] * 5

    def get_writing_style(self) -> Dict[str, str]:
        """
        Returns a generic description. The true style is now defined by the prompt.
        """
        return {
            "concept": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ãå‹•çš„äººæ ¼",
            "target": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã",
            "characteristics": "MDã®æŒ‡ç¤ºã«ã‚ˆã‚Šæ¯å›å¤‰åŒ–"
        }


class WriterAgentManager:
    """Writer ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.writers = {
            "writer1": WriterAgent("writer1"),
            "writer2": WriterAgent("writer2"),
            "writer3": WriterAgent("writer3")
        }
    
    def process_instruction(self, writer_id: str, instruction: str):
        """ç‰¹å®šã®Writerã«æŒ‡ç¤ºå‡¦ç†"""
        if writer_id in self.writers:
            writer = self.writers[writer_id]
            writer.receive_instruction(instruction)
            writer.report_completion()
        else:
            print(f"âŒ ä¸æ˜ãªWriter ID: {writer_id}")
    
    def get_all_writers(self) -> Dict[str, WriterAgent]:
        """å…¨Writerå–å¾—"""
        return self.writers


def main():
    """Writer ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ³•: python writer_agents.py [writer1|writer2|writer3]")
        return
    
    writer_id = sys.argv[1]
    print(f"ğŸš€ {writer_id.upper()} Agent èµ·å‹•...")
    
    manager = WriterAgentManager()
    
    # ãƒ‡ãƒ¢æŒ‡ç¤ºï¼ˆå®Ÿéš›ã¯CDã‹ã‚‰å—ä¿¡ï¼‰
    demo_instruction = """ã€å°æœ¬åˆ¶ä½œæŒ‡ç¤ºã€‘
æˆ¦ç•¥ãƒ–ãƒªãƒ¼ãƒ•: ãƒ©ã‚¯ãƒˆãƒ­ãƒ³è…¸å†…ç’°å¢ƒæ”¹å–„ã‚µãƒ—ãƒªã®å°æœ¬åˆ¶ä½œ
è¦ä»¶: 45-59ç§’ã®å‹•ç”»åºƒå‘Šå°æœ¬
ã‚¹ã‚¿ã‚¤ãƒ«: å„Writerã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸç‹¬è‡ªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
"""
    
    manager.process_instruction(writer_id, demo_instruction)

if __name__ == "__main__":
    main()