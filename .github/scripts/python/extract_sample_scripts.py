#!/usr/bin/env python3
"""
Extract sample scripts for evaluation from internal data (Random Sampling)
Phase 2 Step 1: ãƒ‡ãƒ¼ã‚¿æŠ½å‡º - ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹15æœ¬æŠ½å‡º
"""
import os
import sys
import argparse
import pandas as pd
import json
import logging
import random
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_logging():
    """Setup logging configuration"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def extract_sample_scripts(product_name, data_dir, random_seed=None):
    """å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„ã‚°ãƒ«ãƒ¼ãƒ—5æœ¬ãšã¤ã€è¨ˆ15æœ¬ã®å°æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡º"""
    
    logger = setup_logging()
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
    if random_seed is not None:
        random.seed(random_seed)
        logger.info(f"ğŸ² ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š: {random_seed}")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒ‰ã¯å•†å“åã®ãƒãƒƒã‚·ãƒ¥å€¤
        import hashlib
        seed = int(hashlib.md5(product_name.encode()).hexdigest()[:8], 16)
        random.seed(seed)
        logger.info(f"ğŸ² ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š: {seed} (å•†å“åãƒ™ãƒ¼ã‚¹)")
    
    artifacts_dir = Path(f"{product_name}/artifacts")
    artifacts_dir.mkdir(parents=True, exist_ok=True)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    files = {
        'top': 'internal_top_group.csv',
        'middle': 'internal_middle_group.csv',
        'bottom': 'internal_bottom_group.csv'
    }
    
    extracted_scripts = []
    group_mapping = {}
    
    for group, filename in files.items():
        filepath = Path(data_dir) / filename
        if not filepath.exists():
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            continue
        
        try:
            # CSVã‚’èª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°è¡Œã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾å¿œï¼‰
            df = pd.read_csv(filepath, encoding='utf-8')
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
            df = df.reset_index(drop=True)
            logger.info(f"ğŸ“Š {group}ã‚°ãƒ«ãƒ¼ãƒ—: {len(df)}æœ¬ã®å°æœ¬")
            
            # ã‚«ãƒ©ãƒ åã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å–å¾—
            logger.debug(f"åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {df.columns.tolist()}")
            
            # å°æœ¬ã‚«ãƒ©ãƒ ã®ç‰¹å®š
            content_col = None
            if 'å°æœ¬' in df.columns:
                content_col = 'å°æœ¬'
            elif 'script' in df.columns:
                content_col = 'script'
            elif 'content' in df.columns:
                content_col = 'content'
            elif len(df.columns) > 0:
                content_col = df.columns[0]  # æœ€åˆã®ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
            
            # ã‚¹ã‚³ã‚¢ã‚«ãƒ©ãƒ ã®ç‰¹å®š
            score_col = None
            if 'CTRÃ—CVR' in df.columns:
                score_col = 'CTRÃ—CVR'
            elif 'score' in df.columns:
                score_col = 'score'
            elif 'CVR' in df.columns:
                score_col = 'CVR'
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«5æœ¬ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒ¼ã‚¿ãŒ5æœ¬æœªæº€ã®å ´åˆã¯å…¨ã¦å–å¾—ï¼‰
            if len(df) <= 5:
                sample_scripts = df
                logger.warning(f"âš ï¸ {group}ã‚°ãƒ«ãƒ¼ãƒ—ã¯{len(df)}æœ¬ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ã¦æŠ½å‡ºã—ã¾ã™ã€‚")
            else:
                # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                sample_indices = random.sample(range(len(df)), 5)
                sample_scripts = df.iloc[sample_indices]
                logger.info(f"ğŸ² {group}ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰{len(sample_scripts)}æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡º")
            
            for i, (idx, row) in enumerate(sample_scripts.iterrows()):
                try:
                    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—
                    content = row.get(content_col, '') if content_col else ''
                    
                    # ã‚¹ã‚³ã‚¢ã®å–å¾—ã¨å¤‰æ›
                    score_value = 0
                    if score_col and score_col in row:
                        try:
                            score_value = float(row[score_col])
                        except (ValueError, TypeError):
                            score_value = 0
                    
                    script_data = {
                        'id': f"{group}_{i+1:02d}",  # é€£ç•ªã§IDç”Ÿæˆï¼ˆãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºå¾Œã®é †åºï¼‰
                        'original_group': group,
                        'title': row.get('title', f"{group}_script_{i+1}"),
                        'content': str(content),  # æ–‡å­—åˆ—ã«å¤‰æ›
                        'score': score_value,
                        'metadata': {
                            'source_file': filename,
                            'source_index': idx if isinstance(idx, int) else i,  # ã‚¨ãƒ©ãƒ¼å¯¾ç­–
                            'extraction_order': i + 1  # æŠ½å‡ºå¾Œã®é †åº
                        }
                    }
                    extracted_scripts.append(script_data)
                    group_mapping[script_data['id']] = group
                    
                except Exception as row_error:
                    logger.error(f"âŒ {group}ã‚°ãƒ«ãƒ¼ãƒ—ã®è¡Œ {i} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {row_error}")
                    continue
                    
        except Exception as e:
            logger.error(f"âŒ {group}ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            continue
    
    # æŠ½å‡ºçµæœã‚’ä¿å­˜
    extraction_result = {
        'total_scripts': len(extracted_scripts),
        'groups': {
            'top': len([s for s in extracted_scripts if s['original_group'] == 'top']),
            'middle': len([s for s in extracted_scripts if s['original_group'] == 'middle']),
            'bottom': len([s for s in extracted_scripts if s['original_group'] == 'bottom'])
        },
        'scripts': extracted_scripts,
        'group_mapping': group_mapping,
        'extraction_timestamp': pd.Timestamp.now().isoformat()
    }
    
    # çµæœä¿å­˜
    output_file = artifacts_dir / 'sample_scripts_for_evaluation.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(extraction_result, f, ensure_ascii=False, indent=2)
    
    logger.info(f"âœ… åˆè¨ˆ{len(extracted_scripts)}æœ¬ã®å°æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºã—ã¾ã—ãŸ")
    logger.info(f"ğŸ“ ä¿å­˜å…ˆ: {output_file}")
    logger.info(f"ğŸ“Š å†…è¨³: Top {extraction_result['groups']['top']}æœ¬, Middle {extraction_result['groups']['middle']}æœ¬, Bottom {extraction_result['groups']['bottom']}æœ¬")
    
    return len(extracted_scripts)

def main():
    parser = argparse.ArgumentParser(description='Extract sample scripts for evaluation')
    parser.add_argument('--product-name', required=True, help='Product name')
    parser.add_argument('--data-dir', required=True, help='Directory containing CSV data')
    parser.add_argument('--random-seed', type=int, help='Random seed for reproducible sampling')
    
    args = parser.parse_args()
    
    try:
        scripts_count = extract_sample_scripts(
            args.product_name, 
            args.data_dir, 
            random_seed=args.random_seed
        )
        print(f"scripts_count={scripts_count}")
        print(f"completed={'true' if scripts_count > 0 else 'false'}")
        
    except Exception as e:
        logger = setup_logging()
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã«å¤±æ•—: {str(e)}")
        import traceback
        logger.error(f"è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\n{traceback.format_exc()}")
        print("scripts_count=0")
        print("completed=false")
        sys.exit(1)

if __name__ == "__main__":
    main()
