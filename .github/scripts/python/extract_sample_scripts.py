#!/usr/bin/env python3
"""
Extract sample scripts for evaluation from internal data (Random Sampling)
Phase 2 Step 1: ãƒ‡ãƒ¼ã‚¿æŠ½å‡º - ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹15æœ¬æŠ½å‡º
"""
import os
import sys
import argparse
import pandas as pd
import json
import logging
import random
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_logging():
    """Setup logging configuration"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def extract_sample_scripts(product_name, data_dir, random_seed=None):
    """å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„ã‚°ãƒ«ãƒ¼ãƒ—5æœ¬ãšã¤ã€è¨ˆ15æœ¬ã®å°æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡º"""
    
    logger = setup_logging()
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
    if random_seed is not None:
        random.seed(random_seed)
        logger.info(f"ğŸ² ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š: {random_seed}")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚·ãƒ¼ãƒ‰ã¯å•†å“åã®ãƒãƒƒã‚·ãƒ¥å€¤
        import hashlib
        seed = int(hashlib.md5(product_name.encode()).hexdigest()[:8], 16)
        random.seed(seed)
        logger.info(f"ğŸ² ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š: {seed} (å•†å“åãƒ™ãƒ¼ã‚¹)")
    
    artifacts_dir = Path(f"{product_name}/artifacts")
    artifacts_dir.mkdir(parents=True, exist_ok=True)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    files = {
        'top': 'internal_top_group.csv',
        'middle': 'internal_middle_group.csv',
        'bottom': 'internal_bottom_group.csv'
    }
    
    extracted_scripts = []
    group_mapping = {}
    
    for group, filename in files.items():
        filepath = Path(data_dir) / filename
        if not filepath.exists():
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            continue
        
        df = pd.read_csv(filepath)
        logger.info(f"ğŸ“Š {group}ã‚°ãƒ«ãƒ¼ãƒ—: {len(df)}æœ¬ã®å°æœ¬")
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«5æœ¬ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒ¼ã‚¿ãŒ5æœ¬æœªæº€ã®å ´åˆã¯å…¨ã¦å–å¾—ï¼‰
        if len(df) <= 5:
            sample_scripts = df
            logger.warning(f"âš ï¸ {group}ã‚°ãƒ«ãƒ¼ãƒ—ã¯{len(df)}æœ¬ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ã¦æŠ½å‡ºã—ã¾ã™ã€‚")
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            sample_indices = random.sample(range(len(df)), 5)
            sample_scripts = df.iloc[sample_indices]
            logger.info(f"ğŸ² {group}ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰{len(sample_scripts)}æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡º")
        
        for i, (idx, row) in enumerate(sample_scripts.iterrows()):
            script_data = {
                'id': f"{group}_{i+1:02d}",  # é€£ç•ªã§IDç”Ÿæˆï¼ˆãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºå¾Œã®é †åºï¼‰
                'original_group': group,
                'title': row.get('title', f"{group}_script_{i+1}"),
                'content': row.get('content', row.get('script', '')),
                'score': row.get('score', 0),
                'metadata': {
                    'source_file': filename,
                    'source_index': int(idx),  # å…ƒã®CSVã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                    'extraction_order': i + 1  # æŠ½å‡ºå¾Œã®é †åº
                }
            }
            extracted_scripts.append(script_data)
            group_mapping[script_data['id']] = group
    
    # æŠ½å‡ºçµæœã‚’ä¿å­˜
    extraction_result = {
        'total_scripts': len(extracted_scripts),
        'groups': {
            'top': len([s for s in extracted_scripts if s['original_group'] == 'top']),
            'middle': len([s for s in extracted_scripts if s['original_group'] == 'middle']),
            'bottom': len([s for s in extracted_scripts if s['original_group'] == 'bottom'])
        },
        'scripts': extracted_scripts,
        'group_mapping': group_mapping,
        'extraction_timestamp': pd.Timestamp.now().isoformat()
    }
    
    # çµæœä¿å­˜
    output_file = artifacts_dir / 'sample_scripts_for_evaluation.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(extraction_result, f, ensure_ascii=False, indent=2)
    
    logger.info(f"âœ… åˆè¨ˆ{len(extracted_scripts)}æœ¬ã®å°æœ¬ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºã—ã¾ã—ãŸ")
    logger.info(f"ğŸ“ ä¿å­˜å…ˆ: {output_file}")
    logger.info(f"ğŸ“Š å†…è¨³: Top {extraction_result['groups']['top']}æœ¬, Middle {extraction_result['groups']['middle']}æœ¬, Bottom {extraction_result['groups']['bottom']}æœ¬")
    
    return len(extracted_scripts)

def main():
    parser = argparse.ArgumentParser(description='Extract sample scripts for evaluation')
    parser.add_argument('--product-name', required=True, help='Product name')
    parser.add_argument('--data-dir', required=True, help='Directory containing CSV data')
    parser.add_argument('--random-seed', type=int, help='Random seed for reproducible sampling')
    
    args = parser.parse_args()
    
    try:
        scripts_count = extract_sample_scripts(
            args.product_name, 
            args.data_dir, 
            random_seed=args.random_seed
        )
        print(f"scripts_count={scripts_count}")
        print(f"completed={'true' if scripts_count > 0 else 'false'}")
        
    except Exception as e:
        logger = setup_logging()
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã«å¤±æ•—: {str(e)}")
        print("scripts_count=0")
        print("completed=false")
        sys.exit(1)

if __name__ == "__main__":
    main()
