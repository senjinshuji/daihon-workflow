{
  "filtering_date": "2025-09-08 07:30:58",
  "loop_number": 4,
  "threshold_used": 70.0,
  "total_generated": 20,
  "approved_count": 13,
  "approval_rate": 65.0,
  "writer_adjustment_needed": false,
  "insufficient_writers": [],
  "writer_breakdown": {
    "writer1": {
      "total_scripts": 10,
      "approved_scripts": 6,
      "approval_rate": 60.0,
      "average_score": 67.6,
      "approved_files": [
        {
          "file": "writer1_script_7.md",
          "score": 83.1,
          "rank": 1
        },
        {
          "file": "writer1_script_5.md",
          "score": 78.6,
          "rank": 6
        },
        {
          "file": "writer1_script_3.md",
          "score": 72.36666666666666,
          "rank": 9
        },
        {
          "file": "writer1_script_9.md",
          "score": 72.3,
          "rank": 10
        },
        {
          "file": "writer1_script_4.md",
          "score": 72.13333333333334,
          "rank": 11
        },
        {
          "file": "writer1_script_2.md",
          "score": 70.73333333333333,
          "rank": 13
        }
      ],
      "rejected_files": [
        {
          "file": "writer1_script_1.md",
          "score": 68.66666666666667,
          "rank": 16
        },
        {
          "file": "writer1_script_10.md",
          "score": 57.3,
          "rank": 18
        },
        {
          "file": "writer1_script_6.md",
          "score": 55.0,
          "rank": 19
        },
        {
          "file": "writer1_script_8.md",
          "score": 45.8,
          "rank": 20
        }
      ]
    },
    "writer3": {
      "total_scripts": 5,
      "approved_scripts": 4,
      "approval_rate": 80.0,
      "average_score": 77.52,
      "approved_files": [
        {
          "file": "writer3_script_2.md",
          "score": 82.15,
          "rank": 2
        },
        {
          "file": "writer3_script_5.md",
          "score": 81.3,
          "rank": 3
        },
        {
          "file": "writer3_script_1.md",
          "score": 80.44999999999999,
          "rank": 4
        },
        {
          "file": "writer3_script_4.md",
          "score": 80.35,
          "rank": 5
        }
      ],
      "rejected_files": [
        {
          "file": "writer3_script_3.md",
          "score": 63.349999999999994,
          "rank": 17
        }
      ]
    },
    "writer2": {
      "total_scripts": 5,
      "approved_scripts": 3,
      "approval_rate": 60.0,
      "average_score": 71.91333333333333,
      "approved_files": [
        {
          "file": "writer2_script_3.md",
          "score": 75.86666666666666,
          "rank": 7
        },
        {
          "file": "writer2_script_1.md",
          "score": 73.33333333333333,
          "rank": 8
        },
        {
          "file": "writer2_script_5.md",
          "score": 71.4,
          "rank": 12
        }
      ],
      "rejected_files": [
        {
          "file": "writer2_script_2.md",
          "score": 69.56666666666666,
          "rank": 14
        },
        {
          "file": "writer2_script_4.md",
          "score": 69.39999999999999,
          "rank": 15
        }
      ]
    }
  },
  "approved_scripts": [
    {
      "script_file": "writer1_script_7.md",
      "writer": "writer1",
      "persona_scores": {
        "persona2": 83.1
      },
      "average_weighted_score": 83.1,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 1
    },
    {
      "script_file": "writer3_script_2.md",
      "writer": "writer3",
      "persona_scores": {
        "persona1": 86.8,
        "persona3": 77.5
      },
      "average_weighted_score": 82.15,
      "score_std_deviation": 4.649999999999999,
      "consensus_score": 0.17699115044247793,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "trust_building": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 2
    },
    {
      "script_file": "writer3_script_5.md",
      "writer": "writer3",
      "persona_scores": {
        "persona1": 72.3,
        "persona3": 90.3
      },
      "average_weighted_score": 81.3,
      "score_std_deviation": 9.0,
      "consensus_score": 0.1,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            6,
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.5,
          "std_deviation": 1.5,
          "individual_scores": [
            7,
            10
          ]
        },
        "trust_building": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        }
      },
      "rank": 3
    },
    {
      "script_file": "writer3_script_1.md",
      "writer": "writer3",
      "persona_scores": {
        "persona1": 72.1,
        "persona3": 88.8
      },
      "average_weighted_score": 80.44999999999999,
      "score_std_deviation": 8.350000000000001,
      "consensus_score": 0.106951871657754,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.5,
          "std_deviation": 1.5,
          "individual_scores": [
            7,
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            6,
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "trust_building": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        }
      },
      "rank": 4
    },
    {
      "script_file": "writer3_script_4.md",
      "writer": "writer3",
      "persona_scores": {
        "persona1": 70.7,
        "persona3": 90.0
      },
      "average_weighted_score": 80.35,
      "score_std_deviation": 9.649999999999999,
      "consensus_score": 0.09389671361502348,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            6,
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.5,
          "std_deviation": 1.5,
          "individual_scores": [
            7,
            10
          ]
        },
        "trust_building": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        }
      },
      "rank": 5
    },
    {
      "script_file": "writer1_script_5.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 74.5,
        "persona2": 79.7,
        "persona3": 81.6
      },
      "average_weighted_score": 78.6,
      "score_std_deviation": 3.0011109054259655,
      "consensus_score": 0.24993058768850548,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.666666666666666,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            9
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            7,
            8,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            8,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.666666666666666,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            9,
            8,
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8,
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 0.0,
          "individual_scores": [
            7,
            7,
            7
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            6,
            7,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            8,
            9
          ]
        },
        "trust_building": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            8,
            8
          ]
        }
      },
      "rank": 6
    },
    {
      "script_file": "writer2_script_3.md",
      "writer": "writer2",
      "persona_scores": {
        "persona1": 72.4,
        "persona2": 87.1,
        "persona3": 68.1
      },
      "average_weighted_score": 75.86666666666666,
      "score_std_deviation": 8.134835926775384,
      "consensus_score": 0.10947104118957088,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            7,
            9,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            8,
            9,
            7
          ]
        },
        "usp_strength": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            8,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            8,
            9,
            7
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 1.632993161855452,
          "individual_scores": [
            7,
            9,
            5
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.666666666666667,
          "std_deviation": 1.699673171197595,
          "individual_scores": [
            6,
            9,
            5
          ]
        },
        "flow_naturalness": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            8,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            7,
            9,
            7
          ]
        },
        "trust_building": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            7,
            8,
            7
          ]
        }
      },
      "rank": 7
    },
    {
      "script_file": "writer2_script_1.md",
      "writer": "writer2",
      "persona_scores": {
        "persona1": 70.5,
        "persona2": 90.6,
        "persona3": 58.9
      },
      "average_weighted_score": 73.33333333333333,
      "score_std_deviation": 13.09563116293199,
      "consensus_score": 0.07094396756278297,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            7,
            9,
            6
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.632993161855452,
          "individual_scores": [
            7,
            9,
            5
          ]
        },
        "usp_strength": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            7,
            9,
            6
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            6,
            9,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 2.160246899469287,
          "individual_scores": [
            8,
            9,
            4
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            8
          ]
        },
        "character_edge": {
          "average_score": 7.666666666666667,
          "std_deviation": 2.0548046676563256,
          "individual_scores": [
            8,
            10,
            5
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.666666666666667,
          "std_deviation": 2.494438257849294,
          "individual_scores": [
            6,
            10,
            4
          ]
        },
        "flow_naturalness": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            7,
            9,
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 1.632993161855452,
          "individual_scores": [
            7,
            9,
            5
          ]
        },
        "trust_building": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            7,
            9,
            7
          ]
        }
      },
      "rank": 8
    },
    {
      "script_file": "writer1_script_3.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 81.4,
        "persona2": 56.8,
        "persona3": 78.9
      },
      "average_weighted_score": 72.36666666666666,
      "score_std_deviation": 11.054511396810911,
      "consensus_score": 0.08295649380401728,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            7,
            8
          ]
        },
        "usp_strength": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 2.160246899469287,
          "individual_scores": [
            9,
            4,
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            8
          ]
        },
        "character_edge": {
          "average_score": 6.666666666666667,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            8,
            5,
            7
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.666666666666667,
          "std_deviation": 1.8856180831641267,
          "individual_scores": [
            8,
            4,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 7.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            7,
            6,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.699673171197595,
          "individual_scores": [
            9,
            5,
            8
          ]
        },
        "trust_building": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            8
          ]
        }
      },
      "rank": 9
    },
    {
      "script_file": "writer1_script_9.md",
      "writer": "writer1",
      "persona_scores": {
        "persona2": 72.3
      },
      "average_weighted_score": 72.3,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.0,
          "std_deviation": 0,
          "individual_scores": [
            6
          ]
        },
        "flow_naturalness": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 6.0,
          "std_deviation": 0,
          "individual_scores": [
            6
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        }
      },
      "rank": 10
    },
    {
      "script_file": "writer1_script_4.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 83.7,
        "persona2": 63.2,
        "persona3": 69.5
      },
      "average_weighted_score": 72.13333333333334,
      "score_std_deviation": 8.573732494595856,
      "consensus_score": 0.10445246935450476,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            8,
            7
          ]
        },
        "usp_strength": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.666666666666667,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            9,
            6,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 6.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            8,
            5,
            6
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            7,
            8
          ]
        },
        "character_edge": {
          "average_score": 6.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            8,
            5,
            6
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.333333333333333,
          "std_deviation": 1.8856180831641267,
          "individual_scores": [
            9,
            5,
            5
          ]
        },
        "flow_naturalness": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 6.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            6
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            7,
            8
          ]
        }
      },
      "rank": 11
    },
    {
      "script_file": "writer2_script_5.md",
      "writer": "writer2",
      "persona_scores": {
        "persona1": 64.8,
        "persona2": 88.0,
        "persona3": 61.4
      },
      "average_weighted_score": 71.4,
      "score_std_deviation": 11.819757470721077,
      "consensus_score": 0.07800459581890613,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            6,
            9,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            7,
            9,
            6
          ]
        },
        "usp_strength": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            7,
            9,
            6
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            6,
            9,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 6.666666666666667,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            7,
            8,
            5
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            9,
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 1.632993161855452,
          "individual_scores": [
            7,
            9,
            5
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.0,
          "std_deviation": 2.160246899469287,
          "individual_scores": [
            5,
            9,
            4
          ]
        },
        "flow_naturalness": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            7,
            9,
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 6.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            6,
            8,
            5
          ]
        },
        "trust_building": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            6,
            9,
            7
          ]
        }
      },
      "rank": 12
    },
    {
      "script_file": "writer1_script_2.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 84.7,
        "persona2": 62.4,
        "persona3": 65.1
      },
      "average_weighted_score": 70.73333333333333,
      "score_std_deviation": 9.937247550951367,
      "consensus_score": 0.09143068174524548,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            9,
            7,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 6.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            8,
            6,
            6
          ]
        },
        "usp_strength": {
          "average_score": 7.333333333333333,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            9,
            6,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 6.666666666666667,
          "std_deviation": 1.699673171197595,
          "individual_scores": [
            9,
            5,
            6
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            7,
            8
          ]
        },
        "character_edge": {
          "average_score": 6.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            8,
            5,
            6
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.0,
          "std_deviation": 1.4142135623730951,
          "individual_scores": [
            8,
            5,
            5
          ]
        },
        "flow_naturalness": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            8,
            7,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 6.0,
          "std_deviation": 1.632993161855452,
          "individual_scores": [
            8,
            6,
            4
          ]
        },
        "trust_building": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            9,
            6,
            7
          ]
        }
      },
      "rank": 13
    }
  ],
  "summary": {
    "ready_for_phase4": true,
    "min_scripts_per_writer": 3,
    "writers_meeting_requirement": 3,
    "total_writers": 3
  }
}