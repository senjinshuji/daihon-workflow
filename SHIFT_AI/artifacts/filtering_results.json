{
  "filtering_date": "2025-09-08 03:33:36",
  "loop_number": 10,
  "threshold_used": 70.0,
  "total_generated": 29,
  "approved_count": 22,
  "approval_rate": 75.86,
  "writer_adjustment_needed": false,
  "insufficient_writers": [],
  "writer_breakdown": {
    "writer3": {
      "total_scripts": 7,
      "approved_scripts": 5,
      "approval_rate": 71.42857142857143,
      "average_score": 75.60000000000001,
      "approved_files": [
        {
          "file": "writer3_script1.md",
          "score": 94.1,
          "rank": 1
        },
        {
          "file": "writer3_script5.md",
          "score": 83.7,
          "rank": 7
        },
        {
          "file": "writer3_script3.md",
          "score": 78.35,
          "rank": 13
        },
        {
          "file": "writer3_script_7.md",
          "score": 77.1,
          "rank": 16
        },
        {
          "file": "writer3_script4.md",
          "score": 71.55,
          "rank": 21
        }
      ],
      "rejected_files": [
        {
          "file": "writer3_script2.md",
          "score": 68.7,
          "rank": 23
        },
        {
          "file": "writer3_script_4.md",
          "score": 55.7,
          "rank": 28
        }
      ]
    },
    "writer2": {
      "total_scripts": 7,
      "approved_scripts": 6,
      "approval_rate": 85.71428571428571,
      "average_score": 68.35714285714286,
      "approved_files": [
        {
          "file": "writer2_script_8.md",
          "score": 89.3,
          "rank": 2
        },
        {
          "file": "writer2_script_3.md",
          "score": 87.4,
          "rank": 5
        },
        {
          "file": "writer2_script3.md",
          "score": 78.1,
          "rank": 14
        },
        {
          "file": "writer2_script4.md",
          "score": 77.0,
          "rank": 17
        },
        {
          "file": "writer2_script1.md",
          "score": 73.9,
          "rank": 19
        },
        {
          "file": "writer2_script5.md",
          "score": 72.8,
          "rank": 20
        }
      ],
      "rejected_files": [
        {
          "file": "writer2_script2.md",
          "score": 0.0,
          "rank": 29
        }
      ]
    },
    "writer1": {
      "total_scripts": 15,
      "approved_scripts": 11,
      "approval_rate": 73.33333333333333,
      "average_score": 76.52777777777779,
      "approved_files": [
        {
          "file": "writer1_script_9.md",
          "score": 88.5,
          "rank": 3
        },
        {
          "file": "writer1_script_4.md",
          "score": 88.1,
          "rank": 4
        },
        {
          "file": "writer1_script3.md",
          "score": 84.9,
          "rank": 6
        },
        {
          "file": "writer1_script_1.md",
          "score": 82.0,
          "rank": 8
        },
        {
          "file": "writer1_script_2.md",
          "score": 80.4,
          "rank": 9
        },
        {
          "file": "writer1_script5.md",
          "score": 79.86666666666666,
          "rank": 10
        },
        {
          "file": "writer1_script_3.md",
          "score": 79.5,
          "rank": 11
        },
        {
          "file": "writer1_script1.md",
          "score": 78.9,
          "rank": 12
        },
        {
          "file": "writer1_script4.md",
          "score": 77.5,
          "rank": 15
        },
        {
          "file": "writer1_script_5.md",
          "score": 76.9,
          "rank": 18
        },
        {
          "file": "writer1_script_6.md",
          "score": 71.35,
          "rank": 22
        }
      ],
      "rejected_files": [
        {
          "file": "writer1_script2.md",
          "score": 66.3,
          "rank": 24
        },
        {
          "file": "writer1_script_10.md",
          "score": 66.3,
          "rank": 25
        },
        {
          "file": "writer1_script_7.md",
          "score": 66.2,
          "rank": 26
        },
        {
          "file": "writer1_script_8.md",
          "score": 61.199999999999996,
          "rank": 27
        }
      ]
    }
  },
  "approved_scripts": [
    {
      "script_file": "writer3_script1.md",
      "writer": "writer3",
      "persona_scores": {
        "persona3": 94.1
      },
      "average_weighted_score": 94.1,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "differentiation_clarity": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "usp_strength": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "opening_hook_intensity": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "character_edge": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 10.0,
          "std_deviation": 0,
          "individual_scores": [
            10
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 1
    },
    {
      "script_file": "writer2_script_8.md",
      "writer": "writer2",
      "persona_scores": {
        "persona2": 89.3
      },
      "average_weighted_score": 89.3,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "character_edge": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        }
      },
      "rank": 2
    },
    {
      "script_file": "writer1_script_9.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 88.5
      },
      "average_weighted_score": 88.5,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "usp_strength": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "character_edge": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 3
    },
    {
      "script_file": "writer1_script_4.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 88.1
      },
      "average_weighted_score": 88.1,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "usp_strength": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        }
      },
      "rank": 4
    },
    {
      "script_file": "writer2_script_3.md",
      "writer": "writer2",
      "persona_scores": {
        "persona2": 87.4
      },
      "average_weighted_score": 87.4,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "character_edge": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 5
    },
    {
      "script_file": "writer1_script3.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 77.3,
        "persona3": 92.5
      },
      "average_weighted_score": 84.9,
      "score_std_deviation": 7.600000000000001,
      "consensus_score": 0.11627906976744184,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.5,
          "std_deviation": 1.5,
          "individual_scores": [
            7,
            10
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "usp_strength": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            10
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        }
      },
      "rank": 6
    },
    {
      "script_file": "writer3_script5.md",
      "writer": "writer3",
      "persona_scores": {
        "persona3": 83.7
      },
      "average_weighted_score": 83.7,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 7
    },
    {
      "script_file": "writer1_script_1.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 82.0
      },
      "average_weighted_score": 82.0,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 8
    },
    {
      "script_file": "writer1_script_2.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 80.4
      },
      "average_weighted_score": 80.4,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 9
    },
    {
      "script_file": "writer1_script5.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 86.2,
        "persona2": 74.3,
        "persona3": 79.1
      },
      "average_weighted_score": 79.86666666666666,
      "score_std_deviation": 4.888308046303504,
      "consensus_score": 0.16982807151670146,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            9,
            8,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0.816496580927726,
          "individual_scores": [
            9,
            8,
            7
          ]
        },
        "usp_strength": {
          "average_score": 7.666666666666667,
          "std_deviation": 0.9428090415820634,
          "individual_scores": [
            9,
            7,
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            9,
            8,
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.333333333333334,
          "std_deviation": 0.4714045207910317,
          "individual_scores": [
            9,
            8,
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            9,
            6,
            7
          ]
        },
        "character_edge": {
          "average_score": 7.333333333333333,
          "std_deviation": 1.247219128924647,
          "individual_scores": [
            9,
            6,
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0.0,
          "individual_scores": [
            7,
            7,
            7
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8,
            8
          ]
        }
      },
      "rank": 10
    },
    {
      "script_file": "writer1_script_3.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 79.5
      },
      "average_weighted_score": 79.5,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0,
          "individual_scores": [
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 11
    },
    {
      "script_file": "writer1_script1.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 82.6,
        "persona3": 75.2
      },
      "average_weighted_score": 78.9,
      "score_std_deviation": 3.6999999999999957,
      "consensus_score": 0.2127659574468087,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "usp_strength": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0.0,
          "individual_scores": [
            7,
            7
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        }
      },
      "rank": 12
    },
    {
      "script_file": "writer3_script3.md",
      "writer": "writer3",
      "persona_scores": {
        "persona2": 87.4,
        "persona3": 69.3
      },
      "average_weighted_score": 78.35,
      "score_std_deviation": 9.050000000000004,
      "consensus_score": 0.09950248756218902,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "usp_strength": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "right_brain_impact": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 13
    },
    {
      "script_file": "writer2_script3.md",
      "writer": "writer2",
      "persona_scores": {
        "persona2": 93.1,
        "persona3": 63.1
      },
      "average_weighted_score": 78.1,
      "score_std_deviation": 14.999999999999996,
      "consensus_score": 0.06250000000000001,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "usp_strength": {
          "average_score": 7.5,
          "std_deviation": 2.5,
          "individual_scores": [
            10,
            5
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            10,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 2.5,
          "individual_scores": [
            10,
            5
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "right_brain_impact": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 1.0,
          "individual_scores": [
            10,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 14
    },
    {
      "script_file": "writer1_script4.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 83.7,
        "persona3": 71.3
      },
      "average_weighted_score": 77.5,
      "score_std_deviation": 6.200000000000003,
      "consensus_score": 0.13888888888888884,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "usp_strength": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 9.0,
          "std_deviation": 0.0,
          "individual_scores": [
            9,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "character_edge": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 6.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            6
          ]
        },
        "trust_building": {
          "average_score": 9.0,
          "std_deviation": 0.0,
          "individual_scores": [
            9,
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 15
    },
    {
      "script_file": "writer3_script_7.md",
      "writer": "writer3",
      "persona_scores": {
        "persona2": 77.1
      },
      "average_weighted_score": 77.1,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 16
    },
    {
      "script_file": "writer2_script4.md",
      "writer": "writer2",
      "persona_scores": {
        "persona2": 89.3,
        "persona3": 64.7
      },
      "average_weighted_score": 77.0,
      "score_std_deviation": 12.299999999999997,
      "consensus_score": 0.07518796992481204,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "differentiation_clarity": {
          "average_score": 6.5,
          "std_deviation": 1.5,
          "individual_scores": [
            8,
            5
          ]
        },
        "usp_strength": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "right_brain_impact": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            9,
            6
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 17
    },
    {
      "script_file": "writer1_script_5.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 68.5,
        "persona2": 85.3
      },
      "average_weighted_score": 76.9,
      "score_std_deviation": 8.399999999999999,
      "consensus_score": 0.10638297872340427,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "selection_reason_clarity": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.5,
          "std_deviation": 1.5,
          "individual_scores": [
            6,
            9
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            7,
            9
          ]
        },
        "trust_building": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            9
          ]
        },
        "flow_naturalness": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        }
      },
      "rank": 18
    },
    {
      "script_file": "writer2_script1.md",
      "writer": "writer2",
      "persona_scores": {
        "persona2": 89.6,
        "persona3": 58.2
      },
      "average_weighted_score": 73.9,
      "score_std_deviation": 15.699999999999996,
      "consensus_score": 0.0598802395209581,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "differentiation_clarity": {
          "average_score": 6.0,
          "std_deviation": 2.0,
          "individual_scores": [
            8,
            4
          ]
        },
        "usp_strength": {
          "average_score": 6.5,
          "std_deviation": 2.5,
          "individual_scores": [
            9,
            4
          ]
        },
        "selection_reason_clarity": {
          "average_score": 6.5,
          "std_deviation": 2.5,
          "individual_scores": [
            9,
            4
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.5,
          "std_deviation": 2.5,
          "individual_scores": [
            9,
            4
          ]
        },
        "character_edge": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 2.0,
          "individual_scores": [
            9,
            5
          ]
        },
        "trust_building": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 8.5,
          "std_deviation": 0.5,
          "individual_scores": [
            9,
            8
          ]
        }
      },
      "rank": 19
    },
    {
      "script_file": "writer2_script5.md",
      "writer": "writer2",
      "persona_scores": {
        "persona3": 72.8
      },
      "average_weighted_score": 72.8,
      "score_std_deviation": 0.0,
      "consensus_score": 1.0,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "usp_strength": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "opening_hook_intensity": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.0,
          "std_deviation": 0,
          "individual_scores": [
            6
          ]
        },
        "character_edge": {
          "average_score": 6.0,
          "std_deviation": 0,
          "individual_scores": [
            6
          ]
        },
        "right_brain_impact": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        },
        "trust_building": {
          "average_score": 7.0,
          "std_deviation": 0,
          "individual_scores": [
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 8.0,
          "std_deviation": 0,
          "individual_scores": [
            8
          ]
        }
      },
      "rank": 20
    },
    {
      "script_file": "writer3_script4.md",
      "writer": "writer3",
      "persona_scores": {
        "persona2": 47.3,
        "persona3": 95.8
      },
      "average_weighted_score": 71.55,
      "score_std_deviation": 24.25,
      "consensus_score": 0.039603960396039604,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 7.5,
          "std_deviation": 2.5,
          "individual_scores": [
            5,
            10
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.5,
          "std_deviation": 2.5,
          "individual_scores": [
            5,
            10
          ]
        },
        "usp_strength": {
          "average_score": 7.0,
          "std_deviation": 3.0,
          "individual_scores": [
            4,
            10
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 3.0,
          "individual_scores": [
            4,
            10
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.5,
          "std_deviation": 2.5,
          "individual_scores": [
            5,
            10
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.5,
          "std_deviation": 3.5,
          "individual_scores": [
            3,
            10
          ]
        },
        "character_edge": {
          "average_score": 6.0,
          "std_deviation": 3.0,
          "individual_scores": [
            3,
            9
          ]
        },
        "right_brain_impact": {
          "average_score": 7.0,
          "std_deviation": 3.0,
          "individual_scores": [
            4,
            10
          ]
        },
        "trust_building": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        },
        "flow_naturalness": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            6,
            8
          ]
        }
      },
      "rank": 21
    },
    {
      "script_file": "writer1_script_6.md",
      "writer": "writer1",
      "persona_scores": {
        "persona1": 80.6,
        "persona2": 62.1
      },
      "average_weighted_score": 71.35,
      "score_std_deviation": 9.249999999999996,
      "consensus_score": 0.09756097560975613,
      "detailed_scores": {
        "appeal_direction_clarity": {
          "average_score": 8.0,
          "std_deviation": 1.0,
          "individual_scores": [
            9,
            7
          ]
        },
        "differentiation_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "usp_strength": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "selection_reason_clarity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "opening_hook_intensity": {
          "average_score": 7.0,
          "std_deviation": 1.0,
          "individual_scores": [
            8,
            6
          ]
        },
        "sales_pitch_elimination": {
          "average_score": 8.0,
          "std_deviation": 0.0,
          "individual_scores": [
            8,
            8
          ]
        },
        "who_fmt_usp_integration": {
          "average_score": 6.0,
          "std_deviation": 2.0,
          "individual_scores": [
            8,
            4
          ]
        },
        "character_edge": {
          "average_score": 6.0,
          "std_deviation": 2.0,
          "individual_scores": [
            8,
            4
          ]
        },
        "right_brain_impact": {
          "average_score": 6.5,
          "std_deviation": 0.5,
          "individual_scores": [
            7,
            6
          ]
        },
        "trust_building": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        },
        "flow_naturalness": {
          "average_score": 7.5,
          "std_deviation": 0.5,
          "individual_scores": [
            8,
            7
          ]
        }
      },
      "rank": 22
    }
  ],
  "summary": {
    "ready_for_phase4": true,
    "min_scripts_per_writer": 3,
    "writers_meeting_requirement": 3,
    "total_writers": 3
  }
}